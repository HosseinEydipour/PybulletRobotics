{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Self-Localization Using Particle Filter](#toc1_)    \n",
    "- [Launching pybullet](#toc2_)    \n",
    "- [Initial Settings](#toc3_)    \n",
    "- [define Odometry class](#toc4_)    \n",
    "- [Define Particle Filter Class](#toc5_)    \n",
    "- [Setting Parameters for Mobile Robots](#toc6_)    \n",
    "- [Setting Parameters for Sensors](#toc7_)    \n",
    "- [Setting Up the Environment](#toc8_)    \n",
    "- [Setting Parameters for Particles](#toc9_)    \n",
    "- [Running the Simulation](#toc10_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Self-Localization Using Particle Filter](#toc0_)\n",
    "In this notebook, we will perform self-localization using a particle filter for a mobile robot.\n",
    "\n",
    "(For a manual summarizing the functions available in pybullet, please refer to [here](https://github.com/bulletphysics/bullet3/blob/master/docs/pybullet_quickstartguide.pdf).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Launching pybullet](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 23 2025 19:25:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Mesa\n",
      "GL_RENDERER=llvmpipe (LLVM 20.1.2, 256 bits)\n",
      "GL_VERSION=4.5 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.50\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.5 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.2\n",
      "Vendor = Mesa\n",
      "Renderer = llvmpipe (LLVM 20.1.2, 256 bits)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven = Mesa\n",
      "ven = Mesa\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import pybullet\n",
    "import pybullet_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "physics_client = pybullet.connect(pybullet.GUI) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <a id='toc3_'></a>[Initial Settings](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "pybullet.resetSimulation() # Reset the simulation space\n",
    "pybullet.setAdditionalSearchPath(pybullet_data.getDataPath()) # Add path to necessary data for pybullet\n",
    "pybullet.setGravity(0.0, 0.0, -9.8) # Set gravity to that of Earth\n",
    "time_step = 1./240.\n",
    "# time_step = 0.1\n",
    "pybullet.setTimeStep(time_step)\n",
    "\n",
    "# Load the floor\n",
    "plane_id = pybullet.loadURDF(\"plane.urdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[define Odometry class](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WheelOdometry:\n",
    "    def __init__(self, initial_pose, wheel_radius, wheel_tread, const_right_wheel, const_left_wheel, initial_angle_right_wheel, initial_angle_left_wheel):\n",
    "        \"\"\"\n",
    "        Class for wheel odometry\n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_pose : tuple\n",
    "            Initial position and orientation of the robot (x, y, theta)\n",
    "        wheel_radius : float\n",
    "            Radius of the wheel [m]\n",
    "        wheel_tread : float\n",
    "            Distance between the left and right wheels [m]\n",
    "        const_right_wheel : float\n",
    "            Constant for the right wheel (correction value due to friction and environment)\n",
    "        const_left_wheel : float\n",
    "            Constant for the left wheel (correction value due to friction and environment)\n",
    "        initial_angle_right_wheel : float\n",
    "            Initial angle of the right wheel [rad]\n",
    "        initial_angle_left_wheel : float\n",
    "            Initial angle of the left wheel [rad]\n",
    "        \"\"\"\n",
    "        # Constants related to the size of the wheels\n",
    "        self.WHEEL_DIAMETER = wheel_radius * 2\n",
    "        self.WHEEL_TREAD = wheel_tread\n",
    "\n",
    "        # Constants considering the environment and tire material\n",
    "        self.CONSTANT_RIGHT_WHEEL = const_right_wheel\n",
    "        self.CONSTANT_LEFT_WHEEL = const_left_wheel\n",
    "\n",
    "        # Distance per revolution\n",
    "        self.ONE_REVOLUTION_DISTANCE_RIGHT = math.pi * self.WHEEL_DIAMETER * self.CONSTANT_LEFT_WHEEL\n",
    "        self.ONE_REVOLUTION_DISTANCE_LEFT = math.pi * self.WHEEL_DIAMETER * self.CONSTANT_RIGHT_WHEEL\n",
    "\n",
    "        # Initial position and orientation of the robot (x, y, theta)\n",
    "        self.x = initial_pose[0]\n",
    "        self.y = initial_pose[1]\n",
    "        self.theta = initial_pose[2]\n",
    "\n",
    "        # Previous wheel angles\n",
    "        self.last_angle_right_wheel = initial_angle_right_wheel\n",
    "        self.last_angle_left_wheel = initial_angle_left_wheel\n",
    "\n",
    "    def update_position(self, current_angle_right_wheel, current_angle_left_wheel):\n",
    "        \"\"\"\n",
    "        Update the position and orientation of the robot\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_angle_right_wheel : float\n",
    "            Current angle of the right wheel [rad]\n",
    "        current_angle_left_wheel : float\n",
    "            Current angle of the left wheel [rad]\n",
    "        \"\"\"\n",
    "        # Calculate the small change in rotation angle [ΔΘ] of the left and right wheels\n",
    "        delta_angle_right_wheel = current_angle_right_wheel - self.last_angle_right_wheel\n",
    "        delta_angle_left_wheel = current_angle_left_wheel - self.last_angle_left_wheel\n",
    "\n",
    "        # Calculate the number of revolutions from the small change in rotation angle [Δθ] of the left and right wheels (convert 2π → 1 revolution)\n",
    "        revolution_right_wheel = delta_angle_right_wheel / (2.0 * math.pi)\n",
    "        revolution_left_wheel = delta_angle_left_wheel / (2.0 * math.pi)\n",
    "\n",
    "        # Calculate the distance traveled [m] by the left and right wheels\n",
    "        distance_right_wheel = revolution_right_wheel * self.ONE_REVOLUTION_DISTANCE_RIGHT\n",
    "        distance_left_wheel = revolution_left_wheel * self.ONE_REVOLUTION_DISTANCE_LEFT\n",
    "\n",
    "        # Calculate the average travel distance [m] from the left and right travel distances\n",
    "        distance_avg = (distance_right_wheel + distance_left_wheel) / 2.0\n",
    "\n",
    "        # Update the position and orientation of the robot\n",
    "        self.x += distance_avg * math.cos(self.theta)\n",
    "        self.y += distance_avg * math.sin(self.theta)\n",
    "        self.theta += math.atan2(distance_right_wheel - distance_left_wheel, self.WHEEL_TREAD)\n",
    "\n",
    "        # Keep theta within the range -π to π\n",
    "        if self.theta > math.pi:\n",
    "            self.theta -= 2 * math.pi\n",
    "        elif self.theta < -math.pi:\n",
    "            self.theta += 2 * math.pi\n",
    "\n",
    "        # Save the current wheel angles\n",
    "        self.last_angle_right_wheel = current_angle_right_wheel\n",
    "        self.last_angle_left_wheel = current_angle_left_wheel\n",
    "\n",
    "    def get_position(self):\n",
    "        \"\"\"\n",
    "        Get the position and orientation of the robot\n",
    "        \"\"\"\n",
    "        return self.x, self.y, self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Define Particle Filter Class](#toc0_)\n",
    "We will define the Particle Filter class.\n",
    "\n",
    "In self-localization of a mobile robot, particles in a particle filter are like **virtual replicas** of the actual robot, used to estimate the robot's position and orientation.\n",
    "\n",
    "**Since they are replicas, they are treated as if they can perform odometry calculations and obtain sensor values just like the actual robot**.\n",
    "\n",
    "However, since particles are virtual replicas, they cannot perform odometry calculations or obtain sensor values in the same way as the actual robot. Therefore, we perform pseudo-odometry calculations and obtain pseudo-sensor values to make estimations. (For details, refer to the explanations of each method within the class.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall flow is as follows:\n",
    "1. Initialization of particles: Scatter each particle randomly.\n",
    "    - Implemented in the `__init__(num_particles)` method.\n",
    "2. Update particle positions: Update the positions of the particles based on the \"motion model\" (equivalent to the odometry of a real robot).\n",
    "    - Implemented in the `particle_filter.update_motion_model(v, omega, time_step)` method.\n",
    "3. Update particle sensor values: Obtain the pseudo sensor values mounted on the particles.\n",
    "    - Implemented in the `particle_filter.measurement_sensor()` method.\n",
    "4. Update particle weights: Compare the \"sensor values of the particles\" with the \"sensor values of the real robot\" and update the weights so that particles with smaller errors have larger weights.\n",
    "    - Implemented in the `particle_filter.update_weight(obstacle_distances)` method.\n",
    "5. Resampling: Resample the particles based on their weights. This causes particles to gather at positions with higher weights, i.e., more accurate positions.\n",
    "    - Implemented in the `particle_filter.resampling()` method.\n",
    "6. Estimate particle positions: Estimate the position of the real robot by taking the weighted average of the resampled particle positions.\n",
    "    - Implemented in the `particle_filter.estimate_pose()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class ParticleFilter():\n",
    "    class Particle:\n",
    "        def __init__(self, x: float, y: float, theta: float, num_particles: int):\n",
    "            \"\"\"\n",
    "            Initialize a particle\n",
    "            Parameters\n",
    "            ---\n",
    "            x : float\n",
    "                Particle position x\n",
    "            y : float\n",
    "                Particle position y\n",
    "            theta : float\n",
    "                Particle orientation θ\n",
    "            num_particles : int\n",
    "                Number of particles\n",
    "            \"\"\"\n",
    "            # Particle position and orientation\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            self.theta = theta\n",
    "\n",
    "            # List to store distances between the particle and each obstacle\n",
    "            self.obstacle_distances = []\n",
    "\n",
    "            # Particle weight\n",
    "            self.weight = 1. / num_particles\n",
    "\n",
    "    def __init__(self, init_pos: list, \n",
    "                 num_particles: int, particle_range_x: list, particle_range_y: list, particle_range_theta: list,\n",
    "                 v_noise_dist: float, omega_noise_dist: float, sensor_noise_dist: float, obstacle_positions: list,\n",
    "                 resampling_x_noise_dist: float, resampling_y_noise_dist: float, resampling_theta_noise_dist: float,\n",
    "                 draw_particles=False, particle_size=0.02):\n",
    "        \"\"\"\n",
    "        Initialize the particle filter\n",
    "        Parameters\n",
    "        ---\n",
    "        init_pos : list\n",
    "            Initial position of the robot [x, y, theta]\n",
    "        num_particles : int\n",
    "            Total number of particles\n",
    "        particle_range_x : list\n",
    "            Range of initial particle positions x [min, max]\n",
    "        particle_range_y : list\n",
    "            Range of initial particle positions y [min, max]\n",
    "        particle_range_theta : list\n",
    "            Range of initial particle orientations θ [min, max]\n",
    "        v_noise_dist : float\n",
    "            Variance of velocity noise\n",
    "        omega_noise_dist : float\n",
    "            Variance of angular velocity noise\n",
    "        sensor_noise_dist : float\n",
    "            Variance of sensor noise\n",
    "        resampling_x_noise_dist : float\n",
    "            Variance of x-direction noise during resampling\n",
    "        resampling_y_noise_dist : float\n",
    "            Variance of y-direction noise during resampling\n",
    "        resampling_theta_noise_dist : float\n",
    "            Variance of θ-direction noise during resampling\n",
    "        obstacle_positions : list\n",
    "            Positions of obstacles [[x1, y1], [x2, y2], ...] (assuming obstacles are static and do not move)\n",
    "        draw_particles : bool\n",
    "            Whether to draw particles\n",
    "        particle_size : float\n",
    "            Size of particles (effective only if draw_particles is True)\n",
    "        \"\"\"\n",
    "        # Estimated position by particle filter\n",
    "        self.x = init_pos[0]\n",
    "        self.y = init_pos[1]\n",
    "        self.theta = init_pos[2]\n",
    "\n",
    "        # Settings related to particles\n",
    "        self.num_particles = num_particles\n",
    "        self.v_dist = v_noise_dist\n",
    "        self.omega_dist = omega_noise_dist\n",
    "        self.sensor_noise_dist = sensor_noise_dist\n",
    "        self.resampling_x_noise_dist = resampling_x_noise_dist\n",
    "        self.resampling_y_noise_dist = resampling_y_noise_dist\n",
    "        self.resampling_theta_noise_dist = resampling_theta_noise_dist\n",
    "\n",
    "        # Settings related to obstacles\n",
    "        self.obstacle_positions = obstacle_positions\n",
    "\n",
    "        # Settings for drawing particles\n",
    "        self.draw_particles = draw_particles\n",
    "\n",
    "        # Randomly generate initial positions and orientations of particles\n",
    "        self.particles = []\n",
    "        self.particle_ids = [] # For drawing\n",
    "        for i in range(self.num_particles):\n",
    "            x_init = random.uniform(particle_range_x[0], particle_range_x[1])\n",
    "            y_init = random.uniform(particle_range_y[0], particle_range_y[1])\n",
    "            theta_init = random.uniform(particle_range_theta[0], particle_range_theta[1])\n",
    "            particle = self.Particle(x_init, y_init, theta_init, self.num_particles)\n",
    "            self.particles.append(particle)\n",
    "\n",
    "            # For drawing\n",
    "            if self.draw_particles:\n",
    "                # Create visual for the particle\n",
    "                particle_visual_id = pybullet.createVisualShape(pybullet.GEOM_SPHERE, radius=particle_size, rgbaColor=[0,1,0,1])\n",
    "                particle_id = pybullet.createMultiBody(0, -1, particle_visual_id, [self.particles[i].x, self.particles[i].y, 0.2], useMaximalCoordinates=True)\n",
    "                self.particle_ids.append(particle_id)\n",
    "\n",
    "    def update_motion_model(self, v: float, omega: float, dt: float):\n",
    "        \"\"\"\n",
    "        Update the position of particles\n",
    "            Corresponds to position update by odometry in the actual robot\n",
    "            However, particles are virtual replicas of the actual robot and cannot obtain odometry information using encoders,\n",
    "            so the position is updated based on the motion model using the \"velocity\" and \"angular velocity\" obtained from the actual robot\n",
    "            Also, since the result of odometry in the actual robot is affected by friction and other factors, errors are added when updating the position of particles\n",
    "        Parameters\n",
    "        ---\n",
    "        v : float\n",
    "            Velocity of the actual robot\n",
    "        omega : float\n",
    "            Angular velocity of the actual robot\n",
    "        dt : float\n",
    "            Simulation time step\n",
    "        \"\"\"\n",
    "        for i in range(self.num_particles):\n",
    "            # Generate noise for velocity and angular velocity\n",
    "            v_noise = random.gauss(0, self.v_dist)\n",
    "            omega_noise = random.gauss(0, self.omega_dist)\n",
    "\n",
    "            # Update the position of the particle\n",
    "            self.particles[i].x += (v + v_noise) * math.cos(self.particles[i].theta) * dt\n",
    "            self.particles[i].y += (v + v_noise) * math.sin(self.particles[i].theta) * dt\n",
    "            self.particles[i].theta += (omega + omega_noise) * dt\n",
    "\n",
    "            # Keep theta within the range -π to π\n",
    "            if self.particles[i].theta > math.pi:\n",
    "                self.particles[i].theta -= 2 * math.pi\n",
    "            elif self.particles[i].theta < -math.pi:\n",
    "                self.particles[i].theta += 2 * math.pi\n",
    "\n",
    "            # For drawing\n",
    "            if self.draw_particles:\n",
    "                pybullet.resetBasePositionAndOrientation(self.particle_ids[i], [self.particles[i].x, self.particles[i].y, 0.15], pybullet.getQuaternionFromEuler([0, 0, self.particles[i].theta]))\n",
    "\n",
    "\n",
    "    def measurement_sensor(self):\n",
    "        \"\"\"\n",
    "        Measure the distance to obstacles for each particle (observed value)\n",
    "            Obtain sensor values from the sensors of the particles\n",
    "            However, particles are virtual replicas of the actual robot and do not actually have sensors, so measurements are made using pseudo-sensors\n",
    "            In this case, since the positions of the obstacles are known, the distance between the \"current position of the particle\" and \"each obstacle\" is treated as the sensor value\n",
    "            Also, since the sensor values of the actual robot are affected by noise, noise is added to the pseudo-sensor values of the particles\n",
    "\n",
    "            (Supplement) If the actual robot uses a LiDAR sensor:\n",
    "                Each particle is also given a pseudo-LiDAR sensor to measure the distance to obstacles.\n",
    "                Of course, particles do not actually have LiDAR sensors, so it is necessary to pseudo-reproduce LiDAR\n",
    "                Specifically, prepare an environment map and measure the distance based on that map information\n",
    "                For example, perform ray casting on the map to measure the distance from the \"coordinate position of the particle\" to the \"coordinate position of the black pixel (obstacle)\".\n",
    "                (Note that since measurements are made on the image, it is necessary to convert the measurement results to actual distances. Therefore, it is necessary to prepare an environment map that can convert distances)\n",
    "        \"\"\"\n",
    "        for i in range(self.num_particles):\n",
    "            # Initialize distances to each obstacle\n",
    "            self.particles[i].obstacle_distances = []\n",
    "\n",
    "            # Measure the distance to all obstacles\n",
    "            for obstacle_position in self.obstacle_positions:\n",
    "                # Measure the distance to the obstacle\n",
    "                distance = math.sqrt((self.particles[i].x - obstacle_position[0])**2 + (self.particles[i].y - obstacle_position[1])**2)\n",
    "                distance += random.gauss(0, self.sensor_noise_dist) # Add sensor noise\n",
    "                self.particles[i].obstacle_distances.append(distance)\n",
    "            \n",
    "    def update_weight(self, obstacle_distance_real_robot: list):\n",
    "        \"\"\"\n",
    "        Update the weight of particles\n",
    "            For each particle, calculate the error between the \"sensor value of the actual robot\" and the \"sensor value of the particle (pseudo)\", and calculate the weight based on that error\n",
    "            More specifically, if the error is small, it can be predicted that the position of the particle is close to the position of the actual robot, so the weight is increased\n",
    "            Conversely, if the error is large, it can be predicted that the position of the particle is far from the position of the actual robot, so the weight is decreased\n",
    "        Parameters\n",
    "        ---\n",
    "        obstacle_distance_real_robot : list\n",
    "            Measurement results of the actual robot's sensor [[distance of the first ray], [distance of the second ray], ...]\n",
    "        \"\"\"\n",
    "        for i in range(self.num_particles):\n",
    "            for j in range(len(obstacle_distance_real_robot)):\n",
    "                error = abs((obstacle_distance_real_robot[j] - self.particles[i].obstacle_distances[j])) # Calculate the total error between the \"distance measured by the actual robot's sensor\" and the \"distance measured by the particle's sensor\"\n",
    "                self.particles[i].weight *= self.gaussian_probability(error, math.sqrt(self.sensor_noise_dist)) # Calculate the weight based on the Gaussian distribution from the error (the smaller the error, the larger the weight)\n",
    "            self.particles[i].weight += 1e-300  # Add a small value to prevent the weight from becoming 0\n",
    "        \n",
    "        # Normalize the weights (normalize so that the sum of the weights of all particles is 1, as they are treated as probabilities during resampling)\n",
    "        sum_weight = sum([particle.weight for particle in self.particles])\n",
    "        for i in range(self.num_particles):\n",
    "            self.particles[i].weight /= sum_weight\n",
    "\n",
    "    def gaussian_probability(self, residual: float, sigma: float):\n",
    "        \"\"\"\n",
    "        Probability density function based on Gaussian distribution\n",
    "        Parameters\n",
    "        ---\n",
    "        residual : float\n",
    "            Error\n",
    "        sigma : float   \n",
    "            Standard deviation\n",
    "        \n",
    "        Returns\n",
    "        ---\n",
    "        probability : float\n",
    "            Probability density function based on Gaussian distribution\n",
    "        \"\"\"\n",
    "        coefficient = 1.0 / (math.sqrt(2.0 * math.pi) * sigma)\n",
    "        exponential = math.exp(-0.5 * (residual / sigma) ** 2)\n",
    "        return coefficient * exponential\n",
    "\n",
    "    def resampling(self):\n",
    "        \"\"\"\n",
    "        Resampling\n",
    "            Resample particles based on their weights\n",
    "            Particles with large weights are more likely to be selected multiple times, while particles with small weights are less likely to be selected\n",
    "        \"\"\"\n",
    "        # Preparation for resampling\n",
    "        particle_indices = range(self.num_particles) # Indices of particles\n",
    "        tmp_particles = self.particles # Temporary storage for particles\n",
    "        weights = np.array([particle.weight for particle in self.particles]) # Weights of all particles\n",
    "        rng = np.random.default_rng() # Random number generator\n",
    "\n",
    "        # Resampling\n",
    "        for i in range(self.num_particles):\n",
    "            # Select particles based on their weights\n",
    "            index = rng.choice(particle_indices, p=weights, replace=True) \n",
    "            self.particles[i] = copy.deepcopy(tmp_particles[index])\n",
    "\n",
    "            # Add noise randomly\n",
    "            self.particles[i].x += random.gauss(0, self.resampling_x_noise_dist)\n",
    "            self.particles[i].y += random.gauss(0, self.resampling_y_noise_dist)\n",
    "            self.particles[i].theta += random.gauss(0, self.resampling_theta_noise_dist)\n",
    "\n",
    "            # Reset weight\n",
    "            self.particles[i].weight = 1. / self.num_particles\n",
    "            \n",
    "            # For drawing\n",
    "            if self.draw_particles:\n",
    "                pybullet.resetBasePositionAndOrientation(self.particle_ids[i], [self.particles[i].x, self.particles[i].y, 0.0], pybullet.getQuaternionFromEuler([0, 0, self.particles[i].theta]))\n",
    "\n",
    "    def estimate_pose(self):\n",
    "        \"\"\"\n",
    "        Estimate the position of the actual robot\n",
    "            Estimate the position of the actual robot based on the position and weight information of all particle filters\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the positions and weights of all particles\n",
    "        particle_positions = np.array([[particle.x, particle.y, particle.theta] for particle in self.particles])\n",
    "        particle_weights = np.array([particle.weight for particle in self.particles])\n",
    "\n",
    "        # Calculate the weighted average\n",
    "        estimated_position = np.average(particle_positions, axis=0, weights=particle_weights) # Calculate the weighted average\n",
    "        \n",
    "        # Update the estimated position\n",
    "        self.x = estimated_position[0]\n",
    "        self.y = estimated_position[1]\n",
    "        self.theta = estimated_position[2]\n",
    "\n",
    "    def get_pose(self):\n",
    "        \"\"\"\n",
    "        Return the estimated position of the actual robot by the particle filter\n",
    "        \"\"\"\n",
    "        return self.x, self.y, self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Setting Parameters for Mobile Robots](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices of the joints for the left and right wheels\n",
    "RIGHT_WHEEL_IDX = 0\n",
    "LEFT_WHEEL_IDX = 1\n",
    "\n",
    "# Constants related to the wheels\n",
    "WHEEL_RADIUS = 0.05 # Radius of the wheels (match the radius of the wheels in \"simple_two_wheel_car.urdf\")\n",
    "WHEEL_THREAD = 0.325 # Distance between the wheels (match the distance between the wheels in \"simple_two_wheel_car.urdf\")\n",
    "CONSTANT_RIGHT_WHEEL = 1.0 # Constant for the right wheel (considering the effects of friction and environment)\n",
    "CONSTANT_LEFT_WHEEL = 1.0 # Constant for the left wheel (considering the effects of friction and environment)\n",
    "\n",
    "# Create sliders for translational and rotational velocities\n",
    "linear_vel_slider = pybullet.addUserDebugParameter(\"linear_velocity\", -10, 10, 0)\n",
    "angular_vel_slider = pybullet.addUserDebugParameter(\"angular_velocity\", -10, 10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Setting Parameters for Sensors](#toc0_)\n",
    "\n",
    "This time, instead of using direct sensors, we will obtain the \"position of the sensor link of the mobile robot\" and the \"position of each obstacle\" directly from the simulation. The sensor values will be treated as the distances between these two points with added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position of the sensor link\n",
    "SENSOR_LINK_IDX = 5\n",
    "real_sensor_noise_dist = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[Setting Up the Environment](#toc0_)\n",
    "Place walls, obstacles, and the mobile robot.\n",
    "\n",
    "(If an obstacle is generated in such a way that it collides with the mobile robot, please regenerate it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the walls (surrounding all sides)\n",
    "wall_width = 5\n",
    "wall_height = 0.5\n",
    "wall_thickness = 0.1\n",
    "\n",
    "# Parameters for obstacles\n",
    "obstacle_num = 10\n",
    "size_min = 0.1\n",
    "size_max = 0.3\n",
    "\n",
    "# Create walls\n",
    "wall_collision_id = pybullet.createCollisionShape(pybullet.GEOM_BOX, halfExtents=[wall_width/2, wall_thickness/2, wall_height/2])\n",
    "wall_visual_id = pybullet.createVisualShape(pybullet.GEOM_BOX, halfExtents=[wall_width/2, wall_thickness/2, wall_height/2], rgbaColor=[0.5,0.5,0.5,1])\n",
    "pybullet.createMultiBody(0, wall_collision_id, wall_visual_id, [wall_width/2, -wall_thickness/2, wall_height/2])\n",
    "pybullet.createMultiBody(0, wall_collision_id, wall_visual_id, [wall_width/2, wall_width+wall_thickness/2, wall_height/2])\n",
    "pybullet.createMultiBody(0, wall_collision_id, wall_visual_id, [-wall_thickness/2, wall_width/2, wall_height/2], pybullet.getQuaternionFromEuler([0, 0, math.pi/2]))\n",
    "pybullet.createMultiBody(0, wall_collision_id, wall_visual_id, [wall_width+wall_thickness/2, wall_width/2, wall_height/2], pybullet.getQuaternionFromEuler([0, 0, math.pi/2]))\n",
    "\n",
    "# Randomly set the positions of obstacles\n",
    "obstacles = []\n",
    "for i in range(obstacle_num):\n",
    "    box_size = random.uniform(size_min, size_max)\n",
    "    x_init = random.uniform(0+box_size, wall_width-box_size)\n",
    "    y_init = random.uniform(0+box_size, wall_width-box_size)\n",
    "    yaw = random.uniform(0, math.pi)\n",
    "    # If the obstacle is near the center of the area surrounded by walls, reposition the obstacle\n",
    "    while (wall_width/2-box_size < x_init < wall_width/2+box_size) and (wall_width/2-box_size < y_init < wall_width/2+box_size):\n",
    "        x_init = random.uniform(0+box_size, wall_width-box_size)\n",
    "        y_init = random.uniform(0+box_size, wall_width-box_size)\n",
    "    obstacles.append([box_size, x_init, y_init, yaw])\n",
    "\n",
    "# Place obstacles\n",
    "obstacle_positions = []\n",
    "for obstacle in obstacles:\n",
    "    box_size = obstacle[0]\n",
    "    x_init = obstacle[1]\n",
    "    y_init = obstacle[2]\n",
    "    yaw = obstacle[3]\n",
    "    obstacle_id = pybullet.loadURDF(\"../urdf/simple_box.urdf\", [x_init, y_init, box_size/2], pybullet.getQuaternionFromEuler([0,0,yaw]), globalScaling=box_size*2, useFixedBase=True)\n",
    "    pybullet.changeVisualShape(obstacle_id, -1, rgbaColor=[1, 0, 0, 1])\n",
    "    obstacle_positions.append([x_init, y_init])\n",
    "\n",
    "# Load the robot\n",
    "# Set the initial position to the center of the area surrounded by walls\n",
    "car_start_x = wall_width/2\n",
    "car_start_y = wall_width/2\n",
    "car_start_theta = 0\n",
    "car_start_position = [car_start_x, car_start_y, 0.1]  # Set initial position (x, y, z)\n",
    "car_start_orientation = pybullet.getQuaternionFromEuler([0, 0, car_start_theta])  # Set initial orientation (roll, pitch, yaw)\n",
    "car_id = pybullet.loadURDF(\"../urdf/simple_two_wheel_car.urdf\", car_start_position, car_start_orientation)\n",
    "\n",
    "# Set the camera position for GUI mode\n",
    "camera_distance = wall_width\n",
    "camera_yaw = 180.0 # deg\n",
    "camera_pitch = -90.1 # deg\n",
    "camera_target_position = [wall_width/2, wall_width/2, 0.0]\n",
    "pybullet.resetDebugVisualizerCamera(camera_distance, camera_yaw, camera_pitch, camera_target_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc9_'></a>[Setting Parameters for Particles](#toc0_)\n",
    "Set the parameters related to the particle filter.\n",
    "\n",
    "Since these parameters affect the results of self-localization, try changing the values to see how the results vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Total number of particles\n",
    "num_particles = 100\n",
    "\n",
    "# Set the range to scatter particles initially\n",
    "particle_range_x = [car_start_x-0.5, car_start_x+0.5] # Range of ±0.5m from the initial position of the robot\n",
    "particle_range_y = [car_start_y-0.5, car_start_y+0.5] # Range of ±0.5m from the initial position of the robot\n",
    "particle_range_theta = [car_start_theta-math.radians(-10), car_start_theta+math.radians(10)] # Range of ±10° from the initial orientation of the robot\n",
    "\n",
    "# Set the variance of noise\n",
    "v_noise_dist = 0.01\n",
    "omega_noise_dist = 0.01\n",
    "sensor_noise_dist = 0.01\n",
    "\n",
    "# Noise for resampling\n",
    "resampling_x_noise_dist = 0.01\n",
    "resampling_y_noise_dist = 0.01\n",
    "resampling_theta_noise_dist = 0.001\n",
    "\n",
    "# Set the size of particles (for drawing)\n",
    "particle_size = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[Running the Simulation](#toc0_)\n",
    "\n",
    "When the simulation is run, self-localization using the particle filter will be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【estimated position: (2.74, 2.93)】【true position: (2.73, 2.93)】               "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Initialize debug drawing\n",
    "pybullet.removeAllUserDebugItems()\n",
    "\n",
    "# Get the initial angles of the left and right wheels\n",
    "initial_angle_right_wheel = pybullet.getJointState(car_id, RIGHT_WHEEL_IDX)[0]\n",
    "initial_angle_left_wheel = pybullet.getJointState(car_id, LEFT_WHEEL_IDX)[0]\n",
    "\n",
    "# Initialize the rotation angles of the left and right wheels\n",
    "last_odom_x = car_start_x\n",
    "last_odom_y = car_start_y\n",
    "last_odom_theta = car_start_theta\n",
    "\n",
    "# Instantiate the WheelOdometry class\n",
    "wheel_odometry = WheelOdometry([car_start_x, car_start_y, car_start_theta], initial_angle_right_wheel, initial_angle_left_wheel, WHEEL_RADIUS, WHEEL_THREAD, CONSTANT_RIGHT_WHEEL, CONSTANT_LEFT_WHEEL)\n",
    "\n",
    "# Instantiate the ParticleFilter class\n",
    "particle_filter = ParticleFilter([car_start_x, car_start_y, car_start_theta], num_particles, particle_range_x, particle_range_y, particle_range_theta, v_noise_dist, omega_noise_dist, sensor_noise_dist, obstacle_positions, resampling_x_noise_dist, resampling_y_noise_dist, resampling_theta_noise_dist, draw_particles=True, particle_size=particle_size)\n",
    "\n",
    "# Reset the mobile robot to the initial position\n",
    "pybullet.resetBasePositionAndOrientation(car_id, car_start_position, car_start_orientation)\n",
    "\n",
    "while True:\n",
    "    # Get the values from the sliders\n",
    "    linear_velocity = pybullet.readUserDebugParameter(0)\n",
    "    angular_velocity = pybullet.readUserDebugParameter(1)\n",
    "\n",
    "    # Calculate the command velocities for the left and right wheels from the translational and rotational velocities\n",
    "    right_wheel_velocity = linear_velocity + angular_velocity * WHEEL_THREAD / 2\n",
    "    left_wheel_velocity = linear_velocity - angular_velocity * WHEEL_THREAD / 2\n",
    "\n",
    "    # Set the velocities\n",
    "    pybullet.setJointMotorControl2(car_id, RIGHT_WHEEL_IDX, pybullet.VELOCITY_CONTROL, targetVelocity=right_wheel_velocity)\n",
    "    pybullet.setJointMotorControl2(car_id, LEFT_WHEEL_IDX, pybullet.VELOCITY_CONTROL, targetVelocity=left_wheel_velocity)\n",
    "    pybullet.stepSimulation()\n",
    "\n",
    "    # Get the current rotation angles of the wheels\n",
    "    current_angle_wheel_right = pybullet.getJointState(car_id, RIGHT_WHEEL_IDX)[0]\n",
    "    current_angle_wheel_left = pybullet.getJointState(car_id, LEFT_WHEEL_IDX)[0]\n",
    "\n",
    "    # Calculate odometry\n",
    "    wheel_odometry.update_position(current_angle_wheel_right, current_angle_wheel_left)\n",
    "    odom_x, odom_y, odom_theta = wheel_odometry.get_position()\n",
    "\n",
    "    # Calculate velocity and angular velocity from odometry\n",
    "    v = math.sqrt((odom_x - last_odom_x)**2 + (odom_y - last_odom_y)**2) / time_step\n",
    "    omega = (odom_theta - last_odom_theta) / time_step\n",
    "\n",
    "    # Update odometry\n",
    "    last_odom_x = odom_x\n",
    "    last_odom_y = odom_y\n",
    "    last_odom_theta = odom_theta\n",
    "\n",
    "    # Get the sensor position\n",
    "    sensor_link_position = pybullet.getLinkState(car_id, SENSOR_LINK_IDX)[0]\n",
    "\n",
    "    # Measure the distance to all obstacles\n",
    "    obstacle_distances = []\n",
    "    for obstacle_position in obstacle_positions:\n",
    "        # Calculate the distance between the real robot and the obstacle\n",
    "        #   This time, instead of actually measuring with a sensor, we directly obtain the \"position of the sensor link of the mobile robot\" and the \"position of each obstacle\" from the simulation, and treat the distance between the two points with added noise as the sensor value\n",
    "        #   In other words, we assume that the actual robot has a \"sensor that can measure the distance to obstacle_num obstacles\" (regardless of whether such a sensor actually exists in the real world)\n",
    "        #   * For simplicity, it is not implemented this time, but in reality, it is often the case that the error between the \"LiDAR sensor value of the actual robot\" and the \"(pseudo) LiDAR sensor value of the particle\" is calculated, and the weight is calculated based on that error\n",
    "        distance = math.sqrt((sensor_link_position[0] - obstacle_position[0])**2 + (sensor_link_position[1] - obstacle_position[1])**2) # Distance between the \"position of the sensor link of the mobile robot\" and the \"position of the obstacle\"\n",
    "        distance += random.gauss(0, real_sensor_noise_dist) # Add sensor noise\n",
    "        obstacle_distances.append(distance)\n",
    "    \n",
    "    # Update the particle filter (main process) ############################################################\n",
    "    particle_filter.update_motion_model(v, omega, time_step) # Update the position of each particle based on the motion model (equivalent to position update by odometry)\n",
    "    particle_filter.measurement_sensor() # Measure (pseudo) sensor values for each particle\n",
    "    particle_filter.update_weight(obstacle_distances) # Update the weights of the particles\n",
    "    particle_filter.resampling() # Resampling\n",
    "    particle_filter.estimate_pose() # Estimate the position of the particles\n",
    "    #############################################################################################################\n",
    "    estimated_pose = particle_filter.get_pose() # Get the estimated position by the particle filter\n",
    "\n",
    "    # Display the estimated position and the true position (this time, since the estimation is based only on distance information to obstacles, the yaw angle cannot be correctly estimated, so only x and y are displayed.\n",
    "    # In the case of a sensor like LiDAR, it is possible to estimate the yaw angle as well, as multiple rays can obtain distance information in multiple directions)\n",
    "    true_pose = [pybullet.getBasePositionAndOrientation(car_id)[0][0], pybullet.getBasePositionAndOrientation(car_id)[0][1]]\n",
    "    sys.stdout.write(f\"\\r【estimated position: ({estimated_pose[0]:.2f}, {estimated_pose[1]:.2f})】【true position: ({true_pose[0]:.2f}, {true_pose[1]:.2f})】               \")\n",
    "\n",
    "    time.sleep(time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
