{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [AR Marker Detection](#toc1_)    \n",
    "- [Detecting AR Markers Using Pybullet](#toc2_)    \n",
    "  - [Starting pybullet](#toc2_1_)    \n",
    "  - [Initial Setup for pybullet](#toc2_2_)    \n",
    "  - [Generating the Camera and the Box with AR Marker](#toc2_3_)    \n",
    "  - [Changing the Light Source Position](#toc2_4_)    \n",
    "  - [Defining the Function to Detect AR Markers](#toc2_5_)    \n",
    "  - [Defining Camera Parameters](#toc2_6_)    \n",
    "  - [Defining debugParameter](#toc2_7_)    \n",
    "  - [Running AR Marker Detection](#toc2_8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[AR Marker Detection](#toc0_)\n",
    "\n",
    "In this notebook, we will explain how to obtain the position and orientation of a box with an AR marker attached for use in pybullet.\n",
    "\n",
    "For a manual summarizing the functions available in pybullet, refer to [this link](https://github.com/bulletphysics/bullet3/blob/master/docs/pybullet_quickstartguide.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Detecting AR Markers Using Pybullet](#toc0_)\n",
    "\n",
    "Next, we will explain how to detect AR markers using pybullet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Starting pybullet](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 23 2025 19:25:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Mesa\n",
      "GL_RENDERER=llvmpipe (LLVM 20.1.2, 256 bits)\n",
      "GL_VERSION=4.5 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.50\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.5 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.2\n",
      "Vendor = Mesa\n",
      "Renderer = llvmpipe (LLVM 20.1.2, 256 bits)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven = Mesa\n",
      "ven = Mesa\n"
     ]
    }
   ],
   "source": [
    "import pybullet\n",
    "import pybullet_data\n",
    "physics_client = pybullet.connect(pybullet.GUI) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Initial Setup for pybullet](#toc0_)\n",
    "\n",
    "We will perform initial setup for pybullet, such as creating the floor and setting up the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pybullet.resetSimulation() # Reset the simulation space\n",
    "pybullet.setAdditionalSearchPath(pybullet_data.getDataPath()) # Add paths to necessary data for pybullet\n",
    "pybullet.setGravity(0.0, 0.0, -9.8) # Set gravity as on Earth\n",
    "time_step = 1./240.\n",
    "pybullet.setTimeStep(time_step) # Set the time elapsed per step\n",
    "\n",
    "# Load the floor\n",
    "plane_id = pybullet.loadURDF(\"plane.urdf\")\n",
    "\n",
    "# Set the camera position and other parameters in GUI mode\n",
    "camera_distance = 1.0\n",
    "camera_yaw = -150.0 # deg\n",
    "camera_pitch = -20 # deg\n",
    "camera_target_position = [0.0, 0.0, 0.1]\n",
    "pybullet.resetDebugVisualizerCamera(camera_distance, camera_yaw, camera_pitch, camera_target_position)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Generating the Camera and the Box with AR Marker](#toc0_)\n",
    "\n",
    "Next, we will generate the box with the AR marker attached and the camera model to detect the AR marker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: base_link\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: target_position_vertual_link\n"
     ]
    }
   ],
   "source": [
    "# Load the camera (the camera size is 0.1m x 0.1m x 0.1m, so move it 0.05m in the y-axis direction from the origin to align the camera front with the origin)\n",
    "simple_camera_id = pybullet.loadURDF(\"../urdf/simple_camera.urdf\", [0.0, 0.05, 0.5], pybullet.getQuaternionFromEuler([1.57, 0.0, 0.0]), useFixedBase=True)\n",
    "\n",
    "# Load the box with the AR marker attached\n",
    "# Set the position so that the distance from the front of the AR marker box to the camera front is 1m\n",
    "ar_marker_box_id = pybullet.loadURDF(\"../urdf/ar_marker_box.urdf\", [0.0, -1.07, 0.5], pybullet.getQuaternionFromEuler([0.0, 0.0, 0.0]), useFixedBase=True)\n",
    "\n",
    "# Set the texture (specify the same one as in the urdf file)\n",
    "texture_id = pybullet.loadTexture(\"../texture/ar_marker_box.png\")\n",
    "pybullet.changeVisualShape(ar_marker_box_id, -1, textureUniqueId=texture_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[Changing the Light Source Position](#toc0_)\n",
    "\n",
    "Change the position of the light source to make it easier to detect the AR marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the light source position because the AR marker is hard to recognize with the default light source position\n",
    "pybullet.configureDebugVisualizer(lightPosition=[0, 0, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Defining the Function to Detect AR Markers](#toc0_)\n",
    "\n",
    "Define a function to obtain the position and orientation of the AR marker from the acquired image information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ar_marker_pose(marker_size, aruco_dict, parameters, rgb_img, camera_matrix, dist_coeffs):\n",
    "    \"\"\"\n",
    "    Function to obtain the center position, depth, and orientation of the first detected AR marker\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    marker_size : float\n",
    "        Length of one side of the AR marker (meters)\n",
    "    aruco_dict : cv2.aruco.Dictionary\n",
    "        Dictionary of AR markers\n",
    "    parameters : cv2.aruco.DetectorParameters\n",
    "        Parameters for AR marker detection\n",
    "    rgb_img : numpy.ndarray\n",
    "        Camera image (RGB)\n",
    "    camera_matrix : numpy.ndarray\n",
    "        Camera intrinsic parameter matrix\n",
    "    dist_coeffs : numpy.ndarray\n",
    "        Distortion coefficients\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    marker_pose : numpy.ndarray\n",
    "        Position and orientation of the AR marker (x, y, z, roll, pitch, yaw)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the camera image to OpenCV format\n",
    "    # bgr_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Convert RGB array from PyBullet to uint8 OpenCV format\n",
    "    rgb_img = np.array(rgb_img, dtype=np.uint8)\n",
    "    if rgb_img.ndim == 1:\n",
    "        image_height=480\n",
    "        image_width=640\n",
    "        rgb_img = rgb_img.reshape((image_height, image_width, 4))  # RGBA from PyBullet\n",
    "    rgb_img = rgb_img[:, :, :3]  # Drop alpha channel if present\n",
    "\n",
    "    bgr_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Detect AR markers\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(bgr_img, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Return None if no markers are detected\n",
    "    if ids is None or len(ids) == 0:\n",
    "        return None\n",
    "\n",
    "    # Get the position of the four corners of the first detected marker\n",
    "    corner_position_2d = corners[0][0]\n",
    "\n",
    "    # 3D coordinates of the four corners of the marker\n",
    "    corner_position_3d = np.array([[-marker_size/2, -marker_size/2, 0],\n",
    "                                    [marker_size/2, -marker_size/2, 0],\n",
    "                                    [marker_size/2, marker_size/2, 0],\n",
    "                                    [-marker_size/2, marker_size/2, 0]], dtype=np.float32)\n",
    "    \n",
    "    # Use solvePnP to calculate the distance from the camera to the AR marker\n",
    "    _, rotation_vector, translation_vector = cv2.solvePnP(corner_position_3d, corner_position_2d, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # Get the center position and depth of the marker\n",
    "    tvec = np.array(translation_vector)\n",
    "    x = tvec[0][0]\n",
    "    y = tvec[1][0]\n",
    "    z = tvec[2][0]\n",
    "\n",
    "    # Get the orientation of the marker\n",
    "    rvec = np.array(rotation_vector)\n",
    "    roll = rvec[0][0]\n",
    "    pitch = rvec[1][0]\n",
    "    yaw = rvec[2][0]\n",
    "\n",
    "    # Return the position and orientation of the marker\n",
    "    marker_pose = np.array([x, y, z, roll, pitch, yaw])\n",
    "\n",
    "    return marker_pose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is Grok version of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_ar_marker_pose(marker_size, aruco_dict, parameters, rgb_img, camera_matrix, dist_coeffs):\n",
    "    \"\"\"\n",
    "    Function to obtain the center position, depth, and orientation of the first detected AR marker\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    marker_size : float\n",
    "        Length of one side of the AR marker (meters)\n",
    "    aruco_dict : cv2.aruco.Dictionary\n",
    "        Dictionary of AR markers\n",
    "    parameters : cv2.aruco.DetectorParameters\n",
    "        Parameters for AR marker detection\n",
    "    rgb_img : numpy.ndarray\n",
    "        Camera image (RGB)\n",
    "    camera_matrix : numpy.ndarray\n",
    "        Camera intrinsic parameter matrix\n",
    "    dist_coeffs : numpy.ndarray\n",
    "        Distortion coefficients\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    marker_pose : numpy.ndarray\n",
    "        Position and orientation of the AR marker (x, y, z, roll, pitch, yaw)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure rgb_img is a proper NumPy array and handle PyBullet's flat output\n",
    "    rgb_img = np.asarray(rgb_img)\n",
    "    if rgb_img.ndim == 1:\n",
    "        # Assuming standard PyBullet RGBA output; adjust height/width if different\n",
    "        image_height, image_width = 480, 640  # Replace with your actual values\n",
    "        rgb_img = rgb_img.reshape((image_height, image_width, 4))\n",
    "    if rgb_img.ndim != 3 or rgb_img.shape[2] == 4:\n",
    "        rgb_img = rgb_img[:, :, :3]  # Drop alpha if present, ensure 3 channels\n",
    "\n",
    "    # Convert to uint8 (PyBullet OpenGL returns float64 in [0,1])\n",
    "    if rgb_img.dtype.kind in ['f', 'F']:  # Float types\n",
    "        rgb_img = np.clip(rgb_img * 255, 0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        rgb_img = rgb_img.astype(np.uint8)\n",
    "\n",
    "    # Now safe to convert to BGR\n",
    "    bgr_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Detect AR markers\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(bgr_img, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Return None if no markers are detected\n",
    "    if ids is None or len(ids) == 0:\n",
    "        return None\n",
    "\n",
    "    # Get the position of the four corners of the first detected marker\n",
    "    corner_position_2d = corners[0][0]\n",
    "\n",
    "    # 3D coordinates of the four corners of the marker\n",
    "    corner_position_3d = np.array([[-marker_size/2, -marker_size/2, 0],\n",
    "                                    [marker_size/2, -marker_size/2, 0],\n",
    "                                    [marker_size/2, marker_size/2, 0],\n",
    "                                    [-marker_size/2, marker_size/2, 0]], dtype=np.float32)\n",
    "    \n",
    "    # Use solvePnP to calculate the distance from the camera to the AR marker\n",
    "    _, rotation_vector, translation_vector = cv2.solvePnP(corner_position_3d, corner_position_2d, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # Get the center position and depth of the marker\n",
    "    tvec = np.array(translation_vector)\n",
    "    x = tvec[0][0]\n",
    "    y = tvec[1][0]\n",
    "    z = tvec[2][0]\n",
    "\n",
    "    # Get the orientation of the marker (note: rvec is Rodrigues; for true Euler, use cv2.Rodrigues)\n",
    "    rvec = np.array(rotation_vector)\n",
    "    roll = rvec[0][0]\n",
    "    pitch = rvec[1][0]\n",
    "    yaw = rvec[2][0]\n",
    "\n",
    "    # Return the position and orientation of the marker\n",
    "    marker_pose = np.array([x, y, z, roll, pitch, yaw])\n",
    "\n",
    "    return marker_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[Defining Camera Parameters](#toc0_)\n",
    "\n",
    "Define the parameters of the camera used to detect the AR marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera settings\n",
    "fov = 60\n",
    "image_width = 640\n",
    "image_height = 480\n",
    "aspect = image_width / image_height\n",
    "near = 0.05\n",
    "far = 10\n",
    "projection_matrix = pybullet.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "# Calculate the focal length in the y direction\n",
    "fovRad = np.deg2rad(fov)\n",
    "f = image_height / (2 * np.tan(fovRad / 2))\n",
    "\n",
    "# Camera intrinsic parameters\n",
    "camera_matrix = np.array([[f, 0, image_width/2],\n",
    "                          [0, f, image_height/2],\n",
    "                          [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# Distortion coefficients (assuming no distortion here)\n",
    "dist_coeffs = np.array([0.0, 0.0, 0.0, 0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "# Specify the indices of the \"camera link\" and the \"virtual link for capturing camera images\"\n",
    "CAMERA_LINK_IDX = 0\n",
    "CAMERA_TARGET_LINK_IDX = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_7_'></a>[Defining debugParameter](#toc0_)\n",
    "\n",
    "Define parameters to change the position and orientation of the box with the AR marker attached using sliders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pybullet.addUserDebugParameter(\"camera x\", -4, 4, 0.0)\n",
    "pybullet.addUserDebugParameter(\"camera y\", -4, 4, -1.07) # Set the initial position so that the distance from the front of the AR marker box to the camera front is 1m\n",
    "pybullet.addUserDebugParameter(\"camera z\", -4, 8, 0.5)\n",
    "pybullet.addUserDebugParameter(\"camera roll\", -3.14, 3.14, 0.0)\n",
    "pybullet.addUserDebugParameter(\"camera pitch\", -3.14, 3.14, 0)\n",
    "pybullet.addUserDebugParameter(\"camera yaw\", -3.14, 3.14, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_8_'></a>[Running AR Marker Detection](#toc0_)\n",
    "\n",
    "When you run the code below, the position and orientation of the AR marker detected by the camera will be displayed on the Pybullet GUI screen.\n",
    "\n",
    "Additionally, you can change the position and orientation of the \"box with the AR marker attached\" by moving the sliders on the right side of the GUI screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Size of the AR marker to be detected (specify the length of one side of the AR marker)\n",
    "marker_size = 0.1\n",
    "\n",
    "# Define the dictionary for the AR marker to be detected\n",
    "# aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "# parameters = cv2.aruco.DetectorParameters_create()\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Get the values set in the sliders\n",
    "    camera_x = pybullet.readUserDebugParameter(0)\n",
    "    camera_y = pybullet.readUserDebugParameter(1)\n",
    "    camera_z = pybullet.readUserDebugParameter(2)\n",
    "    camera_roll = pybullet.readUserDebugParameter(3)\n",
    "    camera_pitch = pybullet.readUserDebugParameter(4)\n",
    "    camera_yaw = pybullet.readUserDebugParameter(5)\n",
    "\n",
    "    # Update the position and orientation of the box with the AR marker attached\n",
    "    pybullet.resetBasePositionAndOrientation(ar_marker_box_id, [camera_x, camera_y, camera_z], pybullet.getQuaternionFromEuler([camera_roll, camera_pitch, camera_yaw]))\n",
    "\n",
    "    # Get the position of the camera\n",
    "    camera_link_pose = pybullet.getLinkState(simple_camera_id, CAMERA_LINK_IDX)[0] # Position of the camera link at the end of the arm\n",
    "    camera_target_link_pose = pybullet.getLinkState(simple_camera_id, CAMERA_TARGET_LINK_IDX)[0] # Position of a virtual link set just in front of the camera link\n",
    "\n",
    "    # Compute the view matrix of the camera\n",
    "    view_matrix = pybullet.computeViewMatrix(cameraEyePosition=[camera_link_pose[0], camera_link_pose[1], camera_link_pose[2]], cameraTargetPosition=[camera_target_link_pose[0], camera_target_link_pose[1], camera_target_link_pose[2]], cameraUpVector=[0, 0, 1])\n",
    "\n",
    "    # Get the camera image\n",
    "    _, _, rgb_img, _, _ = pybullet.getCameraImage(\n",
    "        width=image_width,\n",
    "        height=image_height,\n",
    "        viewMatrix=view_matrix,\n",
    "        projectionMatrix=projection_matrix,\n",
    "        renderer=pybullet.ER_BULLET_HARDWARE_OPENGL\n",
    "    )\n",
    "\n",
    "    # Get the position and orientation of the AR marker\n",
    "    marker_pose = detect_ar_marker_pose(marker_size, aruco_dict, parameters, rgb_img, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # If detection fails, continue to the next loop\n",
    "    if marker_pose is None:\n",
    "        continue\n",
    "\n",
    "    # Display the position and orientation of the AR marker\n",
    "    x = marker_pose[0]\n",
    "    y = marker_pose[2]\n",
    "    z = -marker_pose[1]\n",
    "    roll = -marker_pose[3]\n",
    "    pitch = -marker_pose[5]\n",
    "    yaw = -marker_pose[4]\n",
    "    pybullet.addUserDebugText(f\"marker pose ({x:.2f}, {y:.2f}, {z:.2f}, {np.rad2deg(roll):.2f}, {np.rad2deg(pitch):.2f}, {np.rad2deg(yaw):.2f})\", [1.2, 0, 0], textColorRGB=[1, 0, 0], textSize=1.5, lifeTime=0.5)\n",
    "\n",
    "    time.sleep(time_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
